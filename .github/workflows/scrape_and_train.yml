name: Scrape, Transform, Train, Open Merge request

on:
  on:
    schedule:
      - cron: '0 0 1 * *' #Run Cron job every month
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up python
        uses: actions/setup-python@v4
        with:
          python-version: "3.12.1"
          cache: "pip"

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Overwrite middlewares file in Selenium Python library
        run: |
          cp src/load/scraper/static/middlewares.py /opt/hostedtoolcache/Python/3.12.1/x64/lib/python3.12/site-packages/scrapy_selenium/middlewares.py || echo "Failed to copy file"

      - name: Scrape Data
        run: |
          cd src/load/scraper
          scrapy crawl beer-spider -o ../../../res/data/${GITHUB_RUN_NUMBER}raw_data.json
          cd ../../../

      - name: Transform Data
        run: python src/load/transform/mongo_db_import.py -u ${{ secrets.MONGODB_CONNECTIONSTRING }} -i res/data/${GITHUB_RUN_NUMBER}raw_data.json -c beer

      - name: Train Model
        run: python src/model/model.py -u ${{ secrets.MONGODB_CONNECTIONSTRING }} -p ./res/model/${GITHUB_RUN_NUMBER}

      - name: Create Pull Request
        uses: peter-evans/create-pull-request@v6
        with:
          title: 'Scraped and calculated a new model'
          add-paths: res
          branch: model/${GITHUB_RUN_NUMBER}
